logger:
  - class_path: lightning.pytorch.loggers.CSVLogger
    init_args:
      name: csv
      save_dir: logs
  - class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      name: tb
      save_dir: logs
  - class_path: lightning.pytorch.loggers.MLFlowLogger
    init_args:
      save_dir: logs/mlflow
      experiment_name: adalib
      synchronous: true
      # log_model: 'all'
callbacks:
  - class_path: lightning.pytorch.callbacks.ModelCheckpoint
    init_args:
      dirpath: adalib_checkpoints
      monitor: val/loss
      filename: "{version}/{epoch}-{step}"
      save_top_k: 2
      mode: min
      enable_version_counter: true
  - class_path: lightning.pytorch.callbacks.LearningRateMonitor
    init_args:
      logging_interval: step
      log_momentum: false
      log_weight_decay: true
  - class_path: utils.GradientNormLogger
    init_args:
      norm_type: 2.0
      # log_every_n_steps: 5
max_epochs: 3
gradient_clip_val: 1.0
val_check_interval: 50
log_every_n_steps: 5
enable_checkpointing: true
enable_progress_bar: true
enable_model_summary: true
accelerator: gpu
strategy: ddp
devices: [2]